简体中文 | [English](README.md)


- [背景](#背景)
- [赛题表述](#赛题表述)
- [StandaloneTrainning](#StandaloneTrainning)
- [SupernetTrainning](#SupernetTrainning)

# CVPR 2022 NAS workshop Track1 Demo
这是CVPR 2022 NAS workshop Track1独立训练子网络Demo以及supernet训练Demo

# 背景
深度神经网络已经在图像识别、语音识别和机器翻译等任务上广泛应用并取得突破性成果。神经网络结构对最终模型的效果起到了至关重要的作用，传统基于手工设计的方法需要依赖丰富的人工经验和相关背景知识，并可能需要多次尝试和试错，因此，近年来神经网络结构搜索（NAS）技术成为学术界和工业界研究的热点。  

早期的NAS方法通过将每个神经网络在训练数据上都训练到收敛，然后评估其效果，需要耗费大量的算力资源，例如基于强化学习搜索方法在 CIFAR-10 数据集上的搜索，需要使用800个GPU并行搜索一个月左右的时间，阻碍了其在实际业务中的应用。因此业界慢慢开始研究使用基于可微分框架和超网络的轻量级搜索算法，该类方法通过参数共享的方式，研究人员只需要训练一个大的超网络，然后通过继承超网络参数的方式快速的评估每个子网络的性能，从而可以非常高效的进行模型结构自动搜索，但这些方法在灵活性和搜索效果上都还存在一些问题，特别是基于超网络的方法存在的子网络一致性问题一直没有得到很好的解决。  

为了解决神经网络结构搜索的搜索效率和效果问题，百度联合悉尼科技大学和美国北卡罗来纳大学，以轻量级神经网络结构搜索技术为研究课题，提供技术、数据、算力等支持，全球招募挑战者共同切磋交流，打造最前沿的AI模型结构搜索技术。 百度在NAS领域原创性了提出了GP-NAS（CVPR），SA-NAS（IJCV）等AutoDL算法，使用研发的AutoDL算法先后7次CVPR，ECCV等国际比赛夺得世界第一，提交了200余项中国/美国专利申请。并孵化了[PaddleSlim](https://github.com/PaddlePaddle/PaddleSlim)模型压缩平台，PaddleSlim是百度基于飞桨PaddlePaddle打造的开源模型压缩工具库，囊括了深度学习模型压缩领域常用的量化、剪枝、蒸馏、模型结构搜索等方法，并且打造了CV和NLP领域的模型压缩方案。

本次比赛分为两个赛道，赛道一为[超网络赛道](https://aistudio.baidu.com/aistudio/competition/detail/149/0/introduction)，旨在解决OneshotNAS的一致性问题；赛道二为[模型性能预测赛道](https://aistudio.baidu.com/aistudio/competition/detail/150/0/introduction)，旨在不做任何训练的情况，准确的预测任意模型结构在特定评测集的性能。**获胜的队伍会被邀请在[CVPR 2022 NAS workshop](https://www.cvpr-nas.com/)上宣讲队伍的技术方案。 此外，各Track 前三名会被邀请提交论文（extended abstract论文可以不通过cmt系统提交，regular论文需要系统提交) ，论文要求详见[CVPR NAS workshop论文提交页面](https://www.cvpr-nas.com/Paper_Submission)**

# 赛题表述

由于算法的高效性，OneshotNAS逐渐成为研究人员的研究热点。通过参数共享的方式，研究人员不再需要独立训练并评估每个子网络的性能而是只需要训练一个大的超网络，然后通过继承超网络参数的方式快速评估每个子网络的性能，从而可以非常高效的进行模型结构自动搜索。然而，独立训练子网络的性能、性能排序与子网络继承超网络参数的性能、性能排序之间有很大的偏差，从而导致搜索得到结构性能差无法使用。本赛道旨在解决超网络的一致性问题。基于超网络性能与独立训练子网络性能最一致的队伍将获得冠军。  

在本赛道中，超网络基于ResNet48构建搜索空间，网络的层数、网络每层的通道数可以搜索，搜索空间如下：
网络层数：
    1.    对于ResNet结构，共4个stage，每个stage有不同的block数；
    2.    第1、2、4 stage分别有5个block，故这三个stage的block搜索空间为：[2,3,4,5]；
    3.    第3个stage有8个block，此stage的block搜索空间为：[2,3,4,5,6,7,8]。
网络每层通道数：
    1.    对于ResNet结构，4个stage分别对应的基本通道数为：[64， 128，256，512]；
    2.    每个conv层通道放缩比例的有：[1.0, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7]；
    3.    故每个stage中的通道搜索空间为：基本通道数 x [1.0, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7]，且通道数是8的整倍数；
    4.    ResNet结构中第一个conv到第一个stage之间有一个stem conv，基本通道数位64，与其对应的放缩比例仍为：[1.0, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7]，且通道数是8的整倍数；
子模型编码：
我们统一使用模型编码表示超网的子模型，模型的编码共51位，比如：348311131310000332323230014143424241434543757770000，其中：
    1.    子模型编码长度保持为51位；
    2.    第1～4位数字分别表示前4个stage被选取的block数量；
    3.    [1.0, 0.95, 0.9, 0.85, 0.8, 0.75, 0.7]放缩比例分别编码为：1、2、3、4、5、6、7。比如如果编码位3，那么该conv层的channel为：基本通道数 x 0.9，且为8的倍数；
    4.    第5位表示ResNet中stem conv层的通道层的放缩比例对应的编码；
    5.    对于每个stage中，block数量不足，对应的编码会补0。由于每个ResNet block有2个conv，所以每少一个block，补2个0。

近期，我们会Release ResNet48搜索空间中选择**45000个子网络**, 参赛选手需要使用**ImageNet数据集**训练包含ResNet48搜索空间的超网络，然后基于训练好**超网络的参数**评估这45000个子网络的性能，并在榜单提交入口开放之后，将45000个模型结构与这些结构对应的性能提交的服务器。主办方会基于45000个结构中的预先选定的若干个子结构（比赛结束前对参赛者不可见）的排序一致性(Kendall metric)来评估参赛选手的成绩。  

比赛分A/B榜单，A/B榜单都基于选手提交的同一份提交文件，但是计算分数的节点的编号不同。比赛提交截止日期前仅A榜对选手可见，比赛结束后B榜会对选手公布，比赛最终排名按照选手成绩在B榜的排名。为防止选手使用目标结构撞库，A榜榜单指标为Pearson相关系数（和Kendall tau有强相关性）的绝对值，B榜榜单指标为Kendall tau

**重要说明：**  
请参赛选手**务必遵守**以下几点规则:  
1）参赛选手可以根据自己训练的stand alone ground truth (gt) 的精度，调节supernet训练的学习率，batch size, augmentation, 优化器等超参数，但是选手不能使用gt的精度训练超网络, 具体见2)，3)但不仅限于2)，3）只要gt参与到supernet的训练过程就会被判定违规  
2) 基于gt精度与supernet精度的偏差对supernet反向传播会被判定违规  
3) 基于gt的ranking与基于supernet ranking偏差对supernet反向传播会被判定违规  
4) 选手使用任何额外的训练数据训练supernet会被判定违规  
5) 选手通过大量的低精度/固定精度或0精度结构结合少量目标结构的方式对A榜单gt编号进行撞库会被判定违规  
6) 选手最终提交的子网络的精度必须是基于超网络的精度，提交直接训练得到的精度违规，提交经过predictor等方式生成的精度违规  
7) 选手在训练超网络的时候可以使用多个超网络作为监督，比如自监督，孪生超网络等方式，但是最终只能基于1个超网络生成子网络的精度  
8) 最终B榜单前三名选手需要提交代码来复现提交结果，代码包含1)基于训练好的supernet生成选手最终提交结果的模型及脚本，2）复现supernet训练过程的脚本  
9) 第5)点违规可能被提前取消参赛资格，除5)以外违规会在A榜截止后的代码review阶段审核，如果前三名存在违规则最终B榜单排名顺延  

# Standalone Trainning

```bash
pip install -r requirements.txt
python3 -m paddle.distributed.launch --gpu 0,1,2,3 pretrain.py run --arch 1322221222220000122200000024540000000000005525000000 --image_dir /root/paddlejob/workspace/env_run/data/ILSVRC2012/ --batch_size 1024 --max_epoch 90 --warmup 2 > 1322221222220000122200000024540000000000005525000000.log
``` 

# SupernetTrainning
[预训练模型地址](https://aistudio.baidu.com/aistudio/datasetdetail/134077)

```bash
sh train_supernet.sh
``` 
